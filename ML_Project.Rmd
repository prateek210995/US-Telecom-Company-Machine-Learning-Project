---
title: "Machine Learning Project"
---

```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

## Add R libraries here
library(tidyverse)
library(tidymodels)
library(vip)
library(rpart.plot)

# Load the dataset
telecom_df <- read_rds(url('https://gmubusinessanalytics.netlify.app/data/telecom_df.rds'))

```

```{r}
telecom_df
```


# Data Analysis

# Question 1

**Question**: Is there a relation between service cancellation and average monthly international calls?

**Answer**: Yes, the data indicates that the customers who cancel the telecommunication service tend to have a lesser average monthly duration of international calls when compared to those who do not. Among 427 customers who cancel the service, the mean average monthly international call duration was 93.57 minutes. This is around 20 minutes less than the mean of average international call minutes of customers who do not cancel the service.

Among the customers who did not cancel the service, 29% have an average monthly international call minute that is less than or equal to 95 minutes. When looking at customers who did cancel the service, this increased to 49%.

```{r}
telecom_df %>% group_by(canceled_service) %>%
               summarise(Num_Customers = n(), 
                            Min_Intl_mins = min(avg_intl_mins),
                            Avg_Intl_mins = mean(avg_intl_mins),
                            Max_Intl_mins = max(avg_intl_mins),
                            SD_Intl_mins = sd(avg_intl_mins),
                            Perc_greater_mins = mean(avg_intl_mins <= 95))
```

```{r}
ggplot(data = telecom_df, aes(x = avg_intl_mins, fill = canceled_service)) + 
   geom_histogram(aes(y = ..density..), color = "white", bins = 20, alpha=0.8) +
   facet_wrap(~ canceled_service, nrow = 2) +
   labs(title = "1.Customers having average monthly International calls by Status(Service cancelled- Yes/No)",
           x = "Average Monthly Calls(mins)", y = "Proportion of Customers") +
   theme(plot.title = element_text(size = 12))
```
It is visible from the above histogram plot 1 that the majority of customers who did cancel the service have an average monthly international call minutes less than 100.


# Question 2

**Question**: Is there a relation between service cancellation and household dependents? 

**Answer**: The data does not specify that there is a relationship between service cancellation and household dependents. Among 297 customers who have dependents, only 29% of them canceled the service. Out of 878 customers who do not have dependents, 39% did cancel the service. The majority of customers who did not cancel the service is high either with or without dependents. Hence, there is no correlation between service cancellation and household dependents.


```{r}
telecom_df %>% group_by(canceled_service, dependents) %>% 
                  summarise(Num_Customers = n()) %>% 
                  group_by(dependents) %>% 
                  mutate(Total_Cust_Dependents = sum(Num_Customers), 
                  Perc_Cust_Depen = round(Num_Customers/Total_Cust_Dependents, 2))
```

```{r}
telecom_df %>% group_by(canceled_service, dependents) %>% 
                  summarise(Num_Customers = n()) %>%
                  ggplot(aes(dependents, Num_Customers, fill = canceled_service)) + geom_bar(stat = "identity", alpha=0.8) +
                  facet_wrap(~ canceled_service, nrow = 2) + 
                  labs(title = "2.Customers Count with Dependents by Status (Service cancelled- Yes/No)",
                  x = "Dependents", y = "Number of Customers")
```
The above bar plot 2 illustrates that the count of customers who did not cancel the service either with or without dependents is higher when compared to customers who did cancel the service.


# Question 3

**Question**: Is there a relation between service cancellation and total number of months with company?

**Answer**: Yes, the data specifies that the customers who cancel the service tend to remain fewer months with the company than those who do not. Among 427 customers who cancel the service, the average total number of months remained with the company is around 17. This is around 21 months less than the average number of months who remained with the company and did not cancel the service.

Among the customers who did not cancel the service, 24.19% of them remained less than or equal to 15 months with the company. When looking at customers who did cancel the service, this increased to 60.88%.

```{r} 
telecom_df %>% group_by(canceled_service) %>%
               summarise(Num_Customers = n(), 
                            Min_Intl_mins = min(months_with_company),
                            Avg_Intl_mins = mean(months_with_company),
                            Max_Intl_mins = max(months_with_company),
                            SD_Intl_mins = sd(months_with_company),
                            pct_months = mean(months_with_company <= 15))

```

```{r}
ggplot(data = telecom_df, aes(canceled_service, months_with_company, fill = canceled_service)) + 
  geom_boxplot(alpha=0.8) + labs(title = "3.Total Months with Company by Status(Service cancelled- Yes/No)",
           x = "Canceled Service", y = "Total months with Company")
```
Box plot 3 represents that the customers who cancel the service have a median of around 10 months who remain with the company. Whereas, it is around 40 months for customers who do not cancel the service.


# Question 4

**Question**: Is there a relation between service cancellation and monthly fees and charges?

**Answer**: The data does not indicate that there is a relationship between service cancellation and monthly fees and charges. The average monthly fees and charges for customers who canceled the service are the same as for customers who did not. Among 427 customers who canceled the service, 58% have an average monthly fee and charges greater than or equal to $80. This decreased to only 54% for customers who did not cancel the service.

```{r}
telecom_df %>% group_by(canceled_service) %>%
               summarise(Num_Customers = n(), 
                            Min_mnth_charges = min(monthly_charges),
                            Avg_mnth_charges = mean(monthly_charges),
                            Max_mnth_charges = max(monthly_charges),
                            SD_mnth_charges = sd(monthly_charges),
                            Pct_greater80 = mean(monthly_charges >= 80))
```

```{r}
ggplot(telecom_df, aes(canceled_service, monthly_charges)) + 
  geom_violin(aes(fill = canceled_service), trim = FALSE, alpha=0.7) +
  stat_summary(fun = mean, geom ="point", shape = 23, size = 4) +
  labs(title = "4.Customer's Monthly Fees and Charges by Status(Service cancelled- Yes/No)",
           x = "Canceled Service", y = "Monthly Fees and Charges")
```
The Violin plot shows the distribution shape of the data. The width of the violin plot represents the density of the data points. Higher the width, the more the data points. It is observable from the above violin plot 4 that the density of customers throughout the plot with monthly fees and charges is almost the same for both the customers who either canceled or did not cancel the service. The mean monthly fees and charges are around $80 for both the customers who did or did not cancel the service.


# Question 5

**Question**: Is there a relation between service cancellation and device protection?

**Answer**: The data does not indicate that there is a relationship between service cancellation and device protection. Among 143 customers who have device protection, only 27% did cancel the service. Out of 284 customers who do not have device protection, 44% canceled the service. The majority of customers who did not cancel the service are high either with or without device protection. Hence, there is no correlation between service cancellation and device protection.

```{r}
telecom_df %>% group_by(canceled_service, device_protection) %>% 
                  summarise(Num_Customers = n()) %>% 
                  group_by(device_protection) %>% 
                  mutate(Total_Cust_Dvc_Prot = sum(Num_Customers), 
                  Perc_Dvc_Prot = round(Num_Customers/Total_Cust_Dvc_Prot, 2))
```

```{r}
telecom_df %>% group_by(canceled_service, device_protection) %>% 
                  summarise(Num_Customers = n()) %>%
                  ggplot(aes(device_protection, Num_Customers, fill = canceled_service)) + geom_bar(stat = "identity", alpha=0.8) +
                  facet_wrap(~ canceled_service, nrow = 2) + 
                  labs(title = "5.Customers Count with Device Protection by Status(Service cancelled- Yes/No)",
                  x = "Device Protection(Yes / No)", y = "Number of Customers")
```
The above bar plot 5 represents that the count of customers who did not cancel the service either with or without device protection is higher when compared to customers who did cancel the service.



# Machine Learning

# The telecom_df data is split into a training and testing set.

```{r}
set.seed(219)

telecom_split <- initial_split(telecom_df, prop = 0.75, strata = canceled_service)

telecom_train <- telecom_split %>% training()

telecom_test <- telecom_split %>% testing()
```

# Feature Engineering

```{r}
telecom_recipe <- recipe(canceled_service ~ ., data = telecom_train) %>%
                  step_YeoJohnson(all_numeric(), -all_outcomes()) %>%
                  step_normalize(all_numeric(), -all_outcomes()) %>%
                  step_dummy(all_nominal(), -all_outcomes())
```

```{r}
telecom_recipe %>% prep(training = telecom_train) %>% bake(new_data = NULL)
```


# Model 1 : Logistic Regression

```{r}
# Specify a logistic regression model
logistic_model <- logistic_reg() %>%
                  set_engine('glm') %>%
                  set_mode('classification')

# Package recipe and model into a workflow
logistic_wf <- workflow() %>%
               add_model(logistic_model) %>%
               add_recipe(telecom_recipe)

# Fit the workflow to the training data
logistic_fit <- logistic_wf %>%
                fit(data = telecom_train)

# Let us explore the trained model
logistic_trained_model <- logistic_fit %>%
                          pull_workflow_fit()

# Variable importance plot
vip(logistic_trained_model)
```
Variable importance plot shows that attributes such as avg_intl_mins, avg_call_mins, months_with_company, and streaming_movies_no are more important than others in predicting the target variable canceled_service.

```{r}
# Let us predict the categories
logistic_pred_categories <- predict(logistic_fit, new_data = telecom_test)
logistic_pred_categories
```

```{r}
# Examine predicted probabilities
logistic_probabilities <- predict(logistic_fit, new_data = telecom_test, type = 'prob')
logistic_probabilities
```

```{r}
# Combine with the true values
log_test_results <- telecom_test %>% select(canceled_service) %>%
                    bind_cols(logistic_pred_categories) %>%
                    bind_cols(logistic_probabilities)
log_test_results
```

```{r}
# Evaluate model performance

# Confusion Matrix
conf_mat(log_test_results, truth = canceled_service, estimate = .pred_class)
```
The model predicted 24 false positives and 30 false negatives.

```{r}
# Sensitivity
sens(log_test_results, truth = canceled_service, estimate = .pred_class)
```
```{r}
# Specificity
spec(log_test_results, truth = canceled_service, estimate = .pred_class)
```
```{r}
# ROC Curve
roc_curve(log_test_results, truth = canceled_service, estimate = .pred_yes)
```

```{r}
# Plot ROC curve
roc_curve(log_test_results, truth = canceled_service, estimate = .pred_yes) %>%
  autoplot()
```
```{r}
# Calculate area under the ROC curve
roc_auc(log_test_results, truth = canceled_service, .pred_yes)
```



# Model 2 : Decision Tree


# Create folds for cross validation on the training set
```{r}
set.seed(219)

telecom_folds <- vfold_cv(telecom_train, v = 5)
```


```{r}
# Specify the decision tree classifier with the hyperparameters
tree_model <- decision_tree(cost_complexity = tune(), 
                            tree_depth = tune(),
                            min_n = tune()) %>%
              set_engine('rpart') %>%
              set_mode('classification')

# Package recipe and model into a workflow
tree_wf <- workflow() %>%
           add_model(tree_model) %>%
           add_recipe(telecom_recipe)
```

```{r}
# Create a grid of hyperparameter values to test
tree_grid <- grid_random(parameters(tree_model), 
                          size = 10)
tree_grid
```


```{r}
# Tune decision tree workflow
set.seed(219)

tree_tuning <- tree_wf %>%
               tune_grid(resamples = telecom_folds, grid = tree_grid)
```

```{r}
# Show the top 5 best models based on roc_auc metric
tree_tuning %>% show_best(metric = 'roc_auc')
```

```{r}
# Select best model based on roc_auc
best_tree <- tree_tuning %>%
             select_best(metric = 'roc_auc')
best_tree
```

```{r}
# Finalize the workflow
final_tree_wf <- tree_wf %>%
                 finalize_workflow(best_tree)
```

```{r}
tree_wf_fit <- final_tree_wf %>%
            fit(data = telecom_train)
```

```{r}
tree_fit <- tree_wf_fit %>%
            pull_workflow_fit()

# Visualize variable importance
vip(tree_fit)
```
Variable importance plot shows that attributes such as months_with_company, monthly_charges, avg_call_mins, and avg_intl_mins are more important than others in predicting the target variable canceled_service.

```{r}
# Let us visualize decision tree
rpart.plot(tree_fit$fit, roundint = FALSE)
```

```{r}
tree_last_fit <- final_tree_wf %>%
                 last_fit(telecom_split)
```

```{r}
# View performance metrics on test data
tree_last_fit %>% collect_metrics()
```

```{r}
# Confusion Matrix
tree_predictions <- tree_last_fit %>% collect_predictions()

conf_mat(tree_predictions, truth = canceled_service, estimate = .pred_class)
```
Decision tree predicted 30 false positives and 37 false negatives.

```{r}
# Sensitivity
sens(tree_predictions, truth = canceled_service, estimate = .pred_class)
```

```{r}
# Specificity
spec(tree_predictions, truth = canceled_service, estimate = .pred_class)
```

```{r}
# ROC curve
tree_predictions %>% roc_curve(truth = canceled_service, estimate = .pred_yes) %>%
                     autoplot()
```

```{r}
# Calculate area under the ROC curve
roc_auc(tree_predictions, truth = canceled_service, .pred_yes)
```



# Model 3 : Random Forest

```{r}
# Specify the random forest model
rf_model <- rand_forest(mtry = tune(),
                        trees = tune(),
                        min_n = tune()) %>%
            set_engine('ranger', importance = 'impurity') %>%
            set_mode('classification')

# Package recipe and model into a workflow
rf_wf <- workflow() %>%
         add_model(rf_model) %>%
         add_recipe(telecom_recipe)
```

```{r}
# Create a grid of hyperparameter values to test
set.seed(219)

rf_grid <- grid_random(mtry() %>% range_set(c(5, 15)),
                       trees(),
                       min_n(),
                       size = 10)
rf_grid
```

```{r}
# Tune random forest workflow
set.seed(219)

rf_tuning <- rf_wf %>%
             tune_grid(resamples = telecom_folds, grid = rf_grid)
```

```{r}
rf_tuning %>% show_best('roc_auc')
```

```{r}
# Select best model based on roc_auc
best_rf <- rf_tuning %>%
           select_best(metric = 'roc_auc')
best_rf
```

```{r}
# Finalize the workflow
final_rf_wf <- rf_wf %>%
               finalize_workflow(best_rf)
```

```{r}
# Fit randome forest model with training set
rf_wf_fit <- final_rf_wf %>%
             fit(data = telecom_train)

rf_fit <- rf_wf_fit %>%
          pull_workflow_fit()

# Visualize variable importance
vip(rf_fit)
```
Variable importance plot shows that attributes such as months_with_company, avg_intl_mins, avg_call_mins, and monthly_charges are more important than others in predicting the target variable canceled_service.

```{r}
# Train and evaluate with last_fit()
rf_last_fit <- final_rf_wf %>%
               last_fit(telecom_split)
```

```{r}
# View performance metrics on test data
rf_last_fit %>% collect_metrics()
```

```{r}
# Confusion Matrix
rf_predictions <- rf_last_fit %>% collect_predictions()

conf_mat(rf_predictions, truth = canceled_service, estimate = .pred_class)
```
Random Forest predicted 21 false positives and 41 false negatives.

```{r}
# Sensitivity
sens(rf_predictions, truth = canceled_service, estimate = .pred_class)
```

```{r}
# Specificity
spec(rf_predictions, truth = canceled_service, estimate = .pred_class)
```

# Note : From Confusion Matrix, we can calculate the error rate of the model as shown below.

# Type 1 error:
False positive rate = 21/(21+166) = 0.1122

#Type 2 error: 
False negative rate = 41/(65+41) = 0.3867


```{r}
# ROC curve
rf_predictions %>% roc_curve(truth = canceled_service, estimate = .pred_yes) %>%
                   autoplot()
```
```{r}
# Calculate area under the ROC curve
roc_auc(rf_predictions, truth = canceled_service, .pred_yes)
```


# ROC Curve

ROC curve represents the trade-off between true-positive rate and false-positive rate. Classifiers that take curves nearer to the top-left corner signify a better performance. The closer the curve moves to the diagonal line of the ROC space, the less accurate the test. When looking at ROC curves of Logistic regression, Decision tree, and Random forest, the random forest model performed the best.

# Area under ROC

The area under the ROC curve shows how much the model is capable of distinguishing between different classes. The higher the value of AUC, the better the model in predicting the classes as did or did not cancel the service. Out of all three models listed below, the AUC value of the random forest model is the highest. Hence, the random forest is the best model in predicting whether a customer canceled service or not.
#       Model                Area under ROC
1. Logistic Regression           0.8794
2. Decision Tree                 0.8084
3. Random Forest                 0.8846



